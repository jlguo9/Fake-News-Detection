{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Events = [\n",
    "    \"ebola-essien-all-rnr-threads\",\n",
    "    \"charliehebdo-all-rnr-threads\",\n",
    "    \"ferguson-all-rnr-threads\",\n",
    "    \"germanwings-crash-all-rnr-threads\",\n",
    "    \"gurlitt-all-rnr-threads\",\n",
    "    \"ottawashooting-all-rnr-threads\",\n",
    "    \"prince-toronto-all-rnr-threads\",\n",
    "    \"putinmissing-all-rnr-threads\",\n",
    "    \"sydneysiege-all-rnr-threads\"\n",
    "]\n",
    "\n",
    "Categories = [\n",
    "    \"rumours\",\n",
    "    \"non-rumours\"\n",
    "]\n",
    "\n",
    "directory = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charliehebdo-all-rnr-threads: \n",
      "rumours: 458\n",
      "non-rumours: 1621\n",
      "\n",
      "ebola-essien-all-rnr-threads: \n",
      "rumours: 14\n",
      "non-rumours: 0\n",
      "\n",
      "ferguson-all-rnr-threads: \n",
      "rumours: 284\n",
      "non-rumours: 859\n",
      "\n",
      "germanwings-crash-all-rnr-threads: \n",
      "rumours: 238\n",
      "non-rumours: 231\n",
      "\n",
      "gurlitt-all-rnr-threads: \n",
      "rumours: 61\n",
      "non-rumours: 77\n",
      "\n",
      "ottawashooting-all-rnr-threads: \n",
      "rumours: 470\n",
      "non-rumours: 420\n",
      "\n",
      "prince-toronto-all-rnr-threads: \n",
      "rumours: 229\n",
      "non-rumours: 4\n",
      "\n",
      "putinmissing-all-rnr-threads: \n",
      "rumours: 126\n",
      "non-rumours: 112\n",
      "\n",
      "sydneysiege-all-rnr-threads: \n",
      "rumours: 522\n",
      "non-rumours: 699\n",
      "\n",
      "In Total:\n",
      "rumours: 2402\n",
      "non_rumours: 4023\n"
     ]
    }
   ],
   "source": [
    "rumour = 0\n",
    "non_rumour = 0\n",
    "\n",
    "for event in os.listdir(directory):\n",
    "    event_name = os.fsdecode(event)\n",
    "    print(event_name+\": \")\n",
    "\n",
    "    combined_json = []  # store the result of merging all meta json into one\n",
    "    sub_path = os.path.join(directory, event_name)\n",
    "    for r in Categories:\n",
    "        cate_path = os.path.join(sub_path, r)\n",
    "        thread_list = os.listdir(cate_path)\n",
    "        print(r+\":\", len(thread_list))\n",
    "\n",
    "        for thread in thread_list:\n",
    "            thread_id = os.fsdecode(thread)\n",
    "            # ignore DS_store files. Use this once and then make it as comment\n",
    "            # if os.path.isfile(os.path.join(cate_path, thread_name)):\n",
    "            #     os.remove(os.path.join(cate_path, thread_name))\n",
    "            thread_folder = os.path.join(cate_path, thread_id)\n",
    "            with open(os.path.join(thread_folder, \"source-tweets\", thread_id+\".json\")) as json_file:\n",
    "                meta_json = json.load(json_file)\n",
    "            # Add key event\n",
    "            meta_json['event'] = event_name\n",
    "            # Add key \"is_rumour\"\n",
    "            if r == \"rumours\":\n",
    "                rumour += 1\n",
    "                meta_json['is_rumour'] = True\n",
    "\n",
    "            else:\n",
    "                non_rumour += 1\n",
    "                meta_json['is_rumour'] = False\n",
    "            # Add key \"structure\" by extracting structure from structure.json\n",
    "            with open(os.path.join(thread_folder, \"structure.json\")) as json_file:\n",
    "                structure_json = json.load(json_file)\n",
    "            meta_json['structure'] = structure_json\n",
    "            combined_json.append(meta_json)\n",
    "\n",
    "    # Create output directory if not exists\n",
    "    output_path = os.path.join(os.getcwd(), \"combined_data\", event_name, \"source_tweets\")\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    with open(os.path.join(output_path, 'combined.json'), 'w') as output_file:\n",
    "        json.dump(combined_json, output_file)\n",
    "\n",
    "    df = pd.DataFrame.from_records(combined_json)\n",
    "    df = df.set_index('id')\n",
    "    df.to_csv(os.path.join(output_path, 'combined.csv'))\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"In Total:\")\n",
    "print(\"rumours:\", str(rumour))\n",
    "print(\"non_rumours:\", str(non_rumour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in Events:\n",
    "    combined_json = []\n",
    "    for r in Categories:\n",
    "        cate_path = os.path.join(directory, event, r)\n",
    "        for thread in os.listdir(cate_path):\n",
    "            thread_id = os.fsdecode(thread)\n",
    "            reaction_path = os.path.join(cate_path, thread_id, \"reactions\")\n",
    "            reaction_list = os.listdir(reaction_path)\n",
    "            for reaction in reaction_list:\n",
    "                reaction_id = os.fsdecode(reaction)\n",
    "                if not reaction_id.startswith(\".\"):\n",
    "                    with open(os.path.join(reaction_path, reaction_id)) as json_file:\n",
    "                        meta_json = json.load(json_file)\n",
    "                    meta_json['event'] = event\n",
    "                    meta_json['thread'] = thread_id\n",
    "                    combined_json.append(meta_json)\n",
    "    \n",
    "    output_path = os.path.join(os.getcwd(), \"combined_data\", event, \"reactions\")\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    with open(os.path.join(output_path, 'combined.json'), 'w') as output_file:\n",
    "        json.dump(combined_json, output_file)\n",
    "\n",
    "    df = pd.DataFrame.from_records(combined_json)\n",
    "    df = df.set_index('id')\n",
    "    df.to_csv(os.path.join(output_path, 'combined.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
