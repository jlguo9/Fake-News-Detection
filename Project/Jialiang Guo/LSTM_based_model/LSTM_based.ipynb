{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchtext.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# specify device\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = torch.cuda.is_available()\n",
    "DROPOUT = .1\n",
    "best_dev_acc = 0.0\n",
    "\n",
    "EMBEDDING_TYPE = 'glove'\n",
    "EPOCHS = 8\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 50\n",
    "BATCH_SIZE = 128\n",
    "USE_BILSTM = True\n",
    "LEARNING_RATE = 5e-5\n",
    "do_freeze_embedding = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19398, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Says the Annies List political group supports ...\n",
       "1      0  When did the decline of coal start? It started...\n",
       "2      0  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3      1  Health care reform legislation is likely to ma...\n",
       "4      0  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# See how the data looks like\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Text Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 65\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len),# - 2\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: test: val = 70:15:15\n",
    "train_text, val_test_text, train_labels, val_test_labels = train_test_split(data['text'], data['label'], test_size=0.3, stratify=data['label'])\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(val_test_text, val_test_labels, test_size=0.5, stratify=val_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "transformed_train = train_text.map(lambda x: text_transform(x))\n",
    "transformed_val = val_text.map(lambda x: text_transform(x))\n",
    "transformed_test = test_text.map(lambda x: text_transform(x))\n",
    "\n",
    "train_X = F.to_tensor(text_transform(train_text.to_list()), padding_value=padding_idx)\n",
    "val_X = F.to_tensor(text_transform(val_text.to_list()), padding_value=padding_idx)\n",
    "test_X = F.to_tensor(text_transform(test_text.to_list()), padding_value=padding_idx)\n",
    "\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_X, train_y)\n",
    "train_sampler = RandomSampler(train_data)                     \n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size=BATCH_SIZE)\n",
    "                                                              \n",
    "val_data = TensorDataset(val_X, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_gpu(v):\n",
    "    return v.cuda() if USE_GPU else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the vocabulary of the data pipeline, so that we can convert word <--> word_index\n",
    "# allowing us to plug in different word embeddings\n",
    "vocab = text_transform[1].vocab.vocab\n",
    "word_to_idx = vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "glove_vectors = GloVe(name=\"6B\")\n",
    "EMBEDDING_DIM = glove_vectors.vectors.shape[1]\n",
    "# prepare random embedding, then fill in glove vectors\n",
    "pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(vocab), EMBEDDING_DIM)).astype('f')\n",
    "pretrained_embeddings[0] = 0\n",
    "for word, wi in glove_vectors.stoi.items():\n",
    "    try:\n",
    "        pretrained_embeddings[word_to_idx[word]-1] = glove_vectors.__getitem__(word)\n",
    "    except KeyError:\n",
    "        pass\n",
    "pretrained_embeddings = maybe_gpu(torch.from_numpy(pretrained_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "class LSTMArch(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, label_size,\n",
    "                 use_gpu, batch_size, dropout=0.5, bidirectional=False, classifier_head=None):\n",
    "        \"\"\"Prepare individual layers\"\"\"\n",
    "        super(LSTMArch, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_gpu = use_gpu\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, bidirectional=bidirectional)\n",
    "        self.hidden2label = nn.Linear(hidden_dim*self.num_directions, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.classifier_head = classifier_head\n",
    "\n",
    "    def init_hidden(self, batch_size=None):\n",
    "        \"\"\"Choose appropriate size and type of hidden layer\"\"\"\n",
    "        if not batch_size:\n",
    "            batch_size = self.batch_size\n",
    "        #what = torch.randn\n",
    "        what = torch.zeros\n",
    "        # first is the hidden h\n",
    "        # second is the cell c\n",
    "        return (maybe_gpu(Variable(what(self.num_directions, batch_size, self.hidden_dim))),\n",
    "                maybe_gpu(Variable(what(self.num_directions, batch_size, self.hidden_dim))))\n",
    "\n",
    "    def classify(self, features):\n",
    "        y = self.hidden2label(features)\n",
    "        log_probs = nnF.log_softmax(y, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        \"\"\"Use the layers of this model to propagate input and return class log probabilities\"\"\"\n",
    "        if self.use_gpu:\n",
    "            sentence = sentence.cuda()\n",
    "        x = self.embeddings(sentence).permute(1,0,2)\n",
    "        batch_size = x.shape[1]\n",
    "        self.hidden = self.init_hidden(batch_size=batch_size)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        features = lstm_out[-1]\n",
    "        log_probs = self.classify(features)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMArch(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM,\n",
    "                            vocab_size=len(vocab), label_size=2,\\\n",
    "                            use_gpu=USE_GPU, batch_size=BATCH_SIZE, dropout=DROPOUT, bidirectional=USE_BILSTM)\n",
    "lstm_model.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=do_freeze_embedding)\n",
    "model = lstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/shared/CMPT/big-data/condaenv/gt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.train()\n",
    "        self.criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        sent_id, labels = batch\n",
    "        output = self.model(sent_id)\n",
    "        loss = self.criteria(output, labels)\n",
    "        \n",
    "        # compute step accuracy\n",
    "        correct_predictions = (output.argmax(1) == labels).sum().item()\n",
    "        total_predictions = len(labels)\n",
    "        acc = correct_predictions / total_predictions\n",
    "        \n",
    "        # pass performance info to logger\n",
    "        self.log(\"train_loss\", loss, on_step = False, on_epoch=True, batch_size=BATCH_SIZE, logger=True)\n",
    "        self.log('train_accuracy', acc, on_step = False, on_epoch=True, batch_size=BATCH_SIZE, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        sent_id, labels = batch\n",
    "        output = self.model(sent_id)\n",
    "        loss = self.criteria(output, labels)\n",
    "        \n",
    "        # compute step accuracy\n",
    "        correct_predictions = (output.argmax(1) == labels).sum().item()\n",
    "        total_predictions = len(labels)\n",
    "        acc = correct_predictions / total_predictions\n",
    "        \n",
    "        # pass performance info to logger\n",
    "        self.log(\"val_loss\", loss, on_step = False, on_epoch=True, batch_size=BATCH_SIZE, logger=True)\n",
    "        self.log('val_accuracy', acc, on_step = False, on_epoch=True, batch_size=BATCH_SIZE, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "tb_logdir = \"logs-proj\"\n",
    "\n",
    "logger = TensorBoardLogger(tb_logdir, name=\"LSTM_model\")\n",
    "trainer = Trainer(logger=logger, max_epochs=EPOCHS)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: logs-proj/LSTM_model\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | model    | LSTMArch         | 75.1 M\n",
      "1 | criteria | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "75.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.1 M    Total params\n",
      "300.566   Total estimated model params size (MB)\n",
      "2023-04-08 15:37:27.796296: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-08 15:37:27.895014: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/shared/CMPT/big-data/condaenv/gt/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/usr/shared/CMPT/big-data/condaenv/gt/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████| 107/107 [00:02<00:00, 43.61it/s, v_num=0]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 60.74it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 2/23 [00:00<00:00, 101.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 132.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 159.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 180.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 197.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 211.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 223.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 234.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 245.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 253.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 259.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 256.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 261.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 266.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 271.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 275.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 276.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 274.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 276.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 280.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 284.51it/s]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████| 107/107 [00:02<00:00, 42.14it/s, v_num=0]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████| 107/107 [00:02<00:00, 44.88it/s, v_num=0]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 60.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▋                 | 2/23 [00:00<00:00, 98.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 127.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 152.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 173.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 191.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 206.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 215.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 219.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 227.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 236.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 243.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 248.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 253.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 258.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 264.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 269.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 274.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 277.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 276.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 277.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 280.66it/s]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████| 107/107 [00:02<00:00, 43.34it/s, v_num=0]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████| 107/107 [00:02<00:00, 44.49it/s, v_num=0]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 61.85it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 2/23 [00:00<00:00, 105.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 136.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 157.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 165.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 177.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 190.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 201.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 204.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 213.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 222.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 230.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 238.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 244.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 244.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 245.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 249.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 253.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 254.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 254.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 258.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 262.08it/s]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████| 107/107 [00:02<00:00, 42.87it/s, v_num=0]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████| 107/107 [00:02<00:00, 44.63it/s, v_num=0]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 59.89it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 2/23 [00:00<00:00, 100.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 128.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 151.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 171.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 188.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 202.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 213.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 223.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 232.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 240.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 244.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 249.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 253.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 257.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 261.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 267.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 271.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 275.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 277.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 279.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 282.36it/s]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████| 107/107 [00:02<00:00, 43.11it/s, v_num=0]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████| 107/107 [00:02<00:00, 44.59it/s, v_num=0]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 63.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 2/23 [00:00<00:00, 106.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 138.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 164.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 178.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 192.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 202.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 208.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 218.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 228.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 237.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 245.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 250.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 256.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 263.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 268.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 273.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 276.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 279.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 281.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 284.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 287.27it/s]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████| 107/107 [00:02<00:00, 43.08it/s, v_num=0]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████| 107/107 [00:02<00:00, 44.58it/s, v_num=0]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 68.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 2/23 [00:00<00:00, 112.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 145.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 166.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 185.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 193.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 202.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 213.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 224.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 234.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 241.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 245.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 250.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 256.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 261.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 265.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 269.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 272.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 274.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 277.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 280.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 284.16it/s]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████| 107/107 [00:02<00:00, 43.02it/s, v_num=0]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████| 107/107 [00:02<00:00, 44.78it/s, v_num=0]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 61.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 2/23 [00:00<00:00, 102.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 131.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 154.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 172.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 188.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 202.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 215.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 224.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 231.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 235.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 239.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 243.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 248.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 244.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 246.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 250.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 253.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 257.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 257.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 257.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 258.93it/s]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████| 107/107 [00:02<00:00, 43.11it/s, v_num=0]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████| 107/107 [00:02<00:00, 44.27it/s, v_num=0]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 1/23 [00:00<00:00, 61.56it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌                | 2/23 [00:00<00:00, 105.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▎               | 3/23 [00:00<00:00, 131.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 4/23 [00:00<00:00, 154.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 5/23 [00:00<00:00, 175.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  26%|████▋             | 6/23 [00:00<00:00, 193.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 7/23 [00:00<00:00, 208.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 8/23 [00:00<00:00, 221.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 9/23 [00:00<00:00, 233.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 10/23 [00:00<00:00, 243.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▏        | 11/23 [00:00<00:00, 251.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▊        | 12/23 [00:00<00:00, 257.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▌       | 13/23 [00:00<00:00, 263.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▎      | 14/23 [00:00<00:00, 268.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████      | 15/23 [00:00<00:00, 267.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▊     | 16/23 [00:00<00:00, 270.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|████████████▌    | 17/23 [00:00<00:00, 274.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 18/23 [00:00<00:00, 279.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████   | 19/23 [00:00<00:00, 284.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|██████████████▊  | 20/23 [00:00<00:00, 287.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████████▌ | 21/23 [00:00<00:00, 288.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████████▎| 22/23 [00:00<00:00, 291.95it/s]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████| 107/107 [00:02<00:00, 42.78it/s, v_num=0]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████| 107/107 [00:02<00:00, 42.76it/s, v_num=0]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████| 107/107 [00:11<00:00,  9.17it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(LitModel(model), train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"LSTM_based.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-gt",
   "language": "python",
   "name": "py-gt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
