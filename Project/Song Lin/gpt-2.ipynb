{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following news article real or fake? Please provide a brief explanation as well.\n",
      "\n",
      "News article:\n",
      "Scientists have discovered a new species of spider in the Amazon rainforest. The spider is unique because it can fly using wings that extend from its abdomen. Researchers believe this adaptation allows the spider to escape predators and search for food more efficiently.\n",
      "\n",
      "Answer:????\n",
      "\n",
      "The spider is a member of the genus Apis mellifera. It is a member of the genus Ap\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "def is_fake_news_gpt2(news_text):\n",
    "    prompt = f\"Is the following news article real or fake? Please provide a brief explanation as well.\\n\\nNews article:\\n{news_text}\\n\\nAnswer: \"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    answer = answer.replace(prompt, \"\").strip()\n",
    "\n",
    "    return answer\n",
    "\n",
    "news_text = \"\"\"Scientists have discovered a new species of spider in the Amazon rainforest. The spider is unique because it can fly using wings that extend from its abdomen. Researchers believe this adaptation allows the spider to escape predators and search for food more efficiently.\"\"\"\n",
    "\n",
    "result = is_fake_news_gpt2(news_text)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "import string\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Remove punctuation\n",
    "    tokens = [''.join(c for c in token if c not in string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Stemming/Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Load and preprocess data\n",
    "data = load_data(\"C:\\\\Users\\\\Alex\\\\Downloads\\\\WELFake_Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Create document vectors using the mean of word vectors\n",
    "def document_vector(tokens, model):\n",
    "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "data['document_vector'] = data['tokens'].apply(lambda x: document_vector(x, word2vec_model))\n",
    "\n",
    "# Extract features (document vectors) and labels\n",
    "X = np.stack(data['document_vector'].values)\n",
    "y = data['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48924097  0.12713179 -0.27337244 ... -0.26956478 -0.13909675\n",
      "   1.03828049]\n",
      " [ 2.66600227  0.05235812 -0.88148677 ... -0.13322905 -0.52463275\n",
      "   0.99650037]\n",
      " [ 0.70893848 -0.34301457  0.21790981 ... -0.39881271  0.02146312\n",
      "  -0.21664295]\n",
      " ...\n",
      " [-0.27936357 -0.64543819  0.28852254 ... -0.36916664 -0.30971491\n",
      "   0.52842015]\n",
      " [ 0.05290093 -0.29853812 -0.04654996 ... -0.12153742  0.16454835\n",
      "   0.71198934]\n",
      " [ 1.42836714 -0.61658293  0.15999073 ... -0.16453208  0.36877975\n",
      "   0.72680187]]\n",
      "[1 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X and y to .npy files\n",
    "np.save('X.npy', X)\n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and y from .npy files\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
