{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>breaking a germanwings airbus a has crashed in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>breaking germanwings ceo plane victims include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a germanwings flight u registration daipx was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>germanwings copilot suffered serious depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>passenger plane carrying  people crashes in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>0</td>\n",
       "      <td>franz marc horses updategurlitt nazitainted ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>0</td>\n",
       "      <td>munich district court has confirmed the applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>0</td>\n",
       "      <td>where should the gurlitt collection go  many p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423</th>\n",
       "      <td>0</td>\n",
       "      <td>possible nazi art transfer riles jewish groups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6424</th>\n",
       "      <td>0</td>\n",
       "      <td>the gurlitt collection should be sold to benef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6425 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         1  breaking a germanwings airbus a has crashed in...\n",
       "1         1  breaking germanwings ceo plane victims include...\n",
       "2         1  a germanwings flight u registration daipx was ...\n",
       "3         1  germanwings copilot suffered serious depressio...\n",
       "4         1  passenger plane carrying  people crashes in th...\n",
       "...     ...                                                ...\n",
       "6420      0  franz marc horses updategurlitt nazitainted ar...\n",
       "6421      0  munich district court has confirmed the applic...\n",
       "6422      0  where should the gurlitt collection go  many p...\n",
       "6423      0  possible nazi art transfer riles jewish groups...\n",
       "6424      0  the gurlitt collection should be sold to benef...\n",
       "\n",
       "[6425 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "def load_pheme_dataset(path_to_pheme):\n",
    "    data = []\n",
    "\n",
    "    for event in os.listdir(path_to_pheme):\n",
    "        event_path = os.path.join(path_to_pheme, event)\n",
    "\n",
    "        if os.path.isdir(event_path):\n",
    "            for rumor_type in [\"rumours\", \"non-rumours\"]:\n",
    "                rumor_path = os.path.join(event_path, rumor_type)\n",
    "                for tweet_id in os.listdir(rumor_path):\n",
    "                    tweet_file = os.path.join(rumor_path, tweet_id, \"source-tweets\", f\"{tweet_id}.json\")\n",
    "\n",
    "                    if os.path.isfile(tweet_file):\n",
    "                        with open(tweet_file, \"r\") as file:\n",
    "                            tweet_data = json.load(file)\n",
    "                            text = tweet_data[\"text\"]\n",
    "                            label = 1 if rumor_type == \"rumours\" else 0\n",
    "                            user_mentions = \" \".join([mention[\"screen_name\"] for mention in tweet_data[\"entities\"][\"user_mentions\"]])\n",
    "                            data.append({\"id\": tweet_id, \"label\": label, \"text\": text, \"user_mentions\": user_mentions})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Keep only alphabetical characters and whitespace\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "\n",
    "def data_pipeline(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data[\"text\"] = data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "    # Only keep label and text columns\n",
    "    data = data[[\"label\", \"text\"]]\n",
    "\n",
    "    # Save the processed data\n",
    "    data.to_csv(\"pheme_processed_data.csv\", index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "path_to_pheme = \"./PHEME/all-rnr-annotated-threads\"\n",
    "data = load_pheme_dataset(path_to_pheme)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "data.to_csv(\"pheme_data.csv\", index=False)\n",
    "\n",
    "# Load data from the CSV file and run the data pipeline\n",
    "data_pipeline(\"pheme_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>on saturday september  at  pm est an explosion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>less than a day after protests over the police...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>obama to un giving up liberty enhances securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>getty images wealth of nations trump vs clinto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>president obama today vetoed a bill that would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>hillarys top donor country just auctioned off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>advertisement  story continues below\\n\\nthe fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>well thats weird if the birther movement is ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\ntheres a lot to be discussed about last ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>people noticed something odd about hillarys ou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0        0  on saturday september  at  pm est an explosion...\n",
       "1        0  less than a day after protests over the police...\n",
       "2        0  obama to un giving up liberty enhances securit...\n",
       "3        0  getty images wealth of nations trump vs clinto...\n",
       "4        0  president obama today vetoed a bill that would...\n",
       "..     ...                                                ...\n",
       "177      1  hillarys top donor country just auctioned off ...\n",
       "178      1  advertisement  story continues below\\n\\nthe fi...\n",
       "179      1  well thats weird if the birther movement is ra...\n",
       "180      1  \\n\\ntheres a lot to be discussed about last ni...\n",
       "181      1  people noticed something odd about hillarys ou...\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_buzzfeed_dataset(buzzfeed_real_path, buzzfeed_fake_path):\n",
    "    buzzfeed_real = pd.read_csv(buzzfeed_real_path)\n",
    "    buzzfeed_fake = pd.read_csv(buzzfeed_fake_path)\n",
    "    buzzfeed_df = pd.concat([buzzfeed_real, buzzfeed_fake])\n",
    "    del buzzfeed_real, buzzfeed_fake\n",
    "\n",
    "    buzzfeed_df[\"type\"] = buzzfeed_df[\"id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    buzzfeed_df = buzzfeed_df[[\"id\", \"title\", \"text\", \"source\", \"type\", \"images\", \"movies\"]]\n",
    "    buzzfeed_df[\"movies\"] = buzzfeed_df[\"movies\"].apply(lambda x: 1 if not pd.isna(x) else 0)\n",
    "    buzzfeed_df[\"images\"] = buzzfeed_df[\"images\"].apply(lambda x: 1 if not pd.isna(x) else 0)\n",
    "\n",
    "    return buzzfeed_df\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def data_pipeline(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    #print(data['type'])\n",
    "    #input()\n",
    "    data[\"text\"] = data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "    data[\"label\"] = data[\"type\"].apply(lambda x: 1 if x == \"Fake\" else 0)\n",
    "\n",
    "    \n",
    "    # Only keep label and text columns\n",
    "    data = data[[\"label\", \"text\"]]\n",
    "\n",
    "    # Save the processed data\n",
    "    data.to_csv(\"buzz_processed_data.csv\", index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "buzzfeed_real_path = \"./buzzfeed/BuzzFeed_real_news_content.csv\"\n",
    "buzzfeed_fake_path = \"./buzzfeed/BuzzFeed_fake_news_content.csv\"\n",
    "data = load_buzzfeed_dataset(buzzfeed_real_path, buzzfeed_fake_path)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "data.to_csv(\"buzzfeed_data.csv\", index=False)\n",
    "\n",
    "# Load data from the CSV file and run the data pipeline\n",
    "data_pipeline(\"buzzfeed_data.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>says the annies list political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>when did the decline of coal start it started ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary clinton agrees with john mccain by vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>the economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0</td>\n",
       "      <td>for the first time in more than a decade impor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>0</td>\n",
       "      <td>says donald trump has bankrupted his companies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0</td>\n",
       "      <td>john mccain and george bush have absolutely no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>1</td>\n",
       "      <td>a new poll shows  percent support the presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>0</td>\n",
       "      <td>no one claims the report vindicating new jerse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0          1  says the annies list political group supports ...\n",
       "1          0  when did the decline of coal start it started ...\n",
       "2          0  hillary clinton agrees with john mccain by vot...\n",
       "3          1  health care reform legislation is likely to ma...\n",
       "4          0  the economic turnaround started at the end of ...\n",
       "...      ...                                                ...\n",
       "12786      0  for the first time in more than a decade impor...\n",
       "12787      0  says donald trump has bankrupted his companies...\n",
       "12788      0  john mccain and george bush have absolutely no...\n",
       "12789      1  a new poll shows  percent support the presiden...\n",
       "12790      0  no one claims the report vindicating new jerse...\n",
       "\n",
       "[12791 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_liar_dataset(train_path, test_path, valid_path):\n",
    "    col_names = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_title\", \"state\", \"party\",\n",
    "                 \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\",\n",
    "                 \"context\"]\n",
    "    train_data = pd.read_csv(train_path, sep='\\t', header=None, names=col_names)\n",
    "    test_data = pd.read_csv(test_path, sep='\\t', header=None, names=col_names)\n",
    "    valid_data = pd.read_csv(valid_path, sep='\\t', header=None, names=col_names)\n",
    "    \n",
    "    data = pd.concat([train_data, test_data, valid_data])\n",
    "    return data\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def data_pipeline(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data[\"statement\"] = data[\"statement\"].apply(preprocess_text)\n",
    "\n",
    "    \n",
    "    data[\"text\"] = data[\"statement\"]\n",
    "    data[\"label\"] = data[\"label\"].apply(lambda x: 1 if x == \"false\" or x == \"pants-fire\" else 0)\n",
    "\n",
    "    # Only keep label and text columns\n",
    "    data = data[[\"label\", \"text\"]]\n",
    "\n",
    "    # Save the processed data\n",
    "    data.to_csv(\"liar_processed_data.csv\", index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "train_path = \"./liar_dataset/train.tsv\"\n",
    "test_path = \"./liar_dataset/test.tsv\"\n",
    "valid_path = \"./liar_dataset/valid.tsv\"\n",
    "data = load_liar_dataset(train_path, test_path, valid_path)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "data.to_csv(\"liar_data.csv\", index=False)\n",
    "\n",
    "# Load data from the CSV file and run the data pipeline\n",
    "data_pipeline(\"liar_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
